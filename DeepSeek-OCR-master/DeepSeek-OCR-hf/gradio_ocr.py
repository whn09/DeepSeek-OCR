import gradio as gr
from transformers import AutoModel, AutoTokenizer
import torch
import os
import tempfile
from pathlib import Path
import re
from PIL import Image
import fitz  # PyMuPDF
import io
import sys
import threading
import time
from queue import Queue


os.environ["CUDA_VISIBLE_DEVICES"] = '0'

# åˆå§‹åŒ–æ¨¡å‹
print("Loading model...")
model_name = 'deepseek-ai/DeepSeek-OCR'
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(
    model_name,
    _attn_implementation='flash_attention_2',
    trust_remote_code=True,
    use_safetensors=True
)
model = model.eval().cuda().to(torch.bfloat16)
print("Model loaded successfully!")


class StreamCapture:
    """æ•è·å¹¶æµå¼è¾“å‡ºæ ‡å‡†è¾“å‡º"""
    def __init__(self):
        self.queue = Queue()
        self.captured_text = []
        self.original_stdout = None
        self.is_capturing = False

    def write(self, text):
        """æ•è·writeè°ƒç”¨"""
        if text and text.strip():
            self.captured_text.append(text)
            self.queue.put(text)
        # åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯
        if self.original_stdout:
            self.original_stdout.write(text)

    def flush(self):
        """flushæ–¹æ³•"""
        if self.original_stdout:
            self.original_stdout.flush()

    def start_capture(self):
        """å¼€å§‹æ•è·"""
        self.original_stdout = sys.stdout
        sys.stdout = self
        self.is_capturing = True
        self.captured_text = []

    def stop_capture(self):
        """åœæ­¢æ•è·"""
        if self.is_capturing:
            sys.stdout = self.original_stdout
            self.is_capturing = False
        return ''.join(self.captured_text)


def pdf_to_images(pdf_path, dpi=144):
    """å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨"""
    images = []
    pdf_document = fitz.open(pdf_path)

    zoom = dpi / 72.0
    matrix = fitz.Matrix(zoom, zoom)

    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        pixmap = page.get_pixmap(matrix=matrix, alpha=False)

        Image.MAX_IMAGE_PIXELS = None
        img_data = pixmap.tobytes("png")
        img = Image.open(io.BytesIO(img_data))

        images.append(img)

    pdf_document.close()
    return images


def extract_image_refs(text):
    """æå–å›¾ç‰‡å¼•ç”¨æ ‡ç­¾"""
    pattern = r'(<\|ref\|>image<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'
    matches = re.findall(pattern, text, re.DOTALL)
    return matches


def extract_coordinates(det_text):
    """ä»detæ ‡ç­¾ä¸­æå–åæ ‡"""
    try:
        coords_list = eval(det_text)
        return coords_list
    except:
        return None


def crop_images_from_text(original_image, ocr_text, output_dir, page_idx=0):
    """æ ¹æ®OCRæ–‡æœ¬ä¸­çš„åæ ‡è£åˆ‡å›¾ç‰‡"""
    if original_image is None or ocr_text is None:
        print("crop_images_from_text: è¾“å…¥ä¸ºç©º")
        return []

    print(f"crop_images_from_text: å¼€å§‹å¤„ç†é¡µé¢ {page_idx}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    # æå–å›¾ç‰‡å¼•ç”¨
    image_refs = extract_image_refs(ocr_text)
    print(f"æ‰¾åˆ° {len(image_refs)} ä¸ªå›¾ç‰‡å¼•ç”¨")

    if not image_refs:
        return []

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)

    # åŠ è½½åŸå§‹å›¾ç‰‡
    if isinstance(original_image, str):
        img = Image.open(original_image)
        print(f"ä»æ–‡ä»¶åŠ è½½å›¾ç‰‡: {original_image}")
    else:
        img = original_image
        print("ä½¿ç”¨PIL Imageå¯¹è±¡")

    image_width, image_height = img.size
    print(f"å›¾ç‰‡å°ºå¯¸: {image_width} x {image_height}")

    cropped_images = []

    for idx, (full_match, coords_str) in enumerate(image_refs):
        print(f"\nå¤„ç†å›¾ç‰‡å¼•ç”¨ {idx+1}: {coords_str}")

        coords_list = extract_coordinates(coords_str)
        if coords_list is None:
            print("  åæ ‡è§£æå¤±è´¥")
            continue

        print(f"  è§£æå‡º {len(coords_list)} ä¸ªåæ ‡æ¡†")

        # å¤„ç†æ¯ä¸ªåæ ‡æ¡†
        for coord_idx, coord in enumerate(coords_list):
            try:
                x1, y1, x2, y2 = coord
                print(f"  æ¡† {coord_idx+1}: åŸå§‹åæ ‡ ({x1}, {y1}) -> ({x2}, {y2})")

                # å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºå®é™…åƒç´ åæ ‡
                px1 = int(x1 / 999 * image_width)
                py1 = int(y1 / 999 * image_height)
                px2 = int(x2 / 999 * image_width)
                py2 = int(y2 / 999 * image_height)

                print(f"  æ¡† {coord_idx+1}: åƒç´ åæ ‡ ({px1}, {py1}) -> ({px2}, {py2})")

                # è£åˆ‡å›¾ç‰‡
                cropped = img.crop((px1, py1, px2, py2))
                print(f"  è£åˆ‡åå°ºå¯¸: {cropped.size}")

                # ä¿å­˜å›¾ç‰‡
                img_filename = f"page{page_idx}_img{len(cropped_images)}.jpg"
                img_path = os.path.join(output_dir, img_filename)
                cropped.save(img_path, quality=95)
                print(f"  ä¿å­˜åˆ°: {img_path}")

                cropped_images.append(img_path)

            except Exception as e:
                print(f"  è£åˆ‡å›¾ç‰‡å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue

    print(f"\næ€»å…±è£åˆ‡äº† {len(cropped_images)} å¼ å›¾ç‰‡")
    return cropped_images


def clean_ocr_output(text, image_refs_replacement=None):
    """æ¸…ç†OCRè¾“å‡ºæ–‡æœ¬"""
    if text is None:
        return ""

    # ç§»é™¤æˆ–æ ¼å¼åŒ–è°ƒè¯•ä¿¡æ¯
    # åŒ¹é…å¼€å¤´çš„è°ƒè¯•å—ï¼š=====================\nBASE: ...\nPATCHES: ...\n=====================
    text = re.sub(r'={5,}\s*BASE:\s+.*?\s+PATCHES:\s+.*?\s+={5,}\s*', '', text, flags=re.DOTALL)

    # åŒ¹é…ç»“å°¾çš„è°ƒè¯•å—ï¼š==================================================\nimage size: ...\n...==================================================
    text = re.sub(r'={10,}\s*image size:.*?={10,}\s*', '', text, flags=re.DOTALL)

    # ç§»é™¤groundingæ ‡ç­¾
    pattern = r'(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'
    matches = re.findall(pattern, text, re.DOTALL)

    # å¦‚æœæä¾›äº†å›¾ç‰‡å¼•ç”¨æ›¿æ¢ï¼Œåˆ™æ›¿æ¢imageæ ‡ç­¾
    img_idx = 0
    for match in matches:
        if '<|ref|>image<|/ref|>' in match[0]:
            if image_refs_replacement:
                # ç”¨å®é™…çš„å›¾ç‰‡é“¾æ¥æ›¿æ¢
                text = text.replace(match[0], image_refs_replacement.format(img_idx), 1)
                img_idx += 1
            else:
                text = text.replace(match[0], '')
        else:
            text = text.replace(match[0], '')

    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
    text = text.replace('\\coloneqq', ':=').replace('\\eqqcolon', '=:')
    text = text.replace('\n\n\n\n', '\n\n').replace('\n\n\n', '\n\n')

    # ç§»é™¤ç»“æŸæ ‡è®°
    if '<ï½œendâ–ofâ–sentenceï½œ>' in text:
        text = text.replace('<ï½œendâ–ofâ–sentenceï½œ>', '')

    return text.strip()


def create_markdown_with_images(ocr_text, image_paths):
    """åˆ›å»ºåŒ…å«å›¾ç‰‡é“¾æ¥çš„Markdownæ–‡æœ¬"""
    if ocr_text is None:
        return ""

    result_text = ocr_text

    # ç§»é™¤æˆ–æ ¼å¼åŒ–è°ƒè¯•ä¿¡æ¯
    # åŒ¹é…å¼€å¤´çš„è°ƒè¯•å—ï¼š=====================\nBASE: ...\nPATCHES: ...\n=====================
    result_text = re.sub(r'={5,}\s*BASE:\s+.*?\s+PATCHES:\s+.*?\s+={5,}\s*', '', result_text, flags=re.DOTALL)

    # åŒ¹é…ç»“å°¾çš„è°ƒè¯•å—ï¼š==================================================\nimage size: ...\n...==================================================
    result_text = re.sub(r'={10,}\s*image size:.*?={10,}\s*', '', result_text, flags=re.DOTALL)

    # ç§»é™¤groundingæ ‡ç­¾ï¼Œä½†ä¿ç•™å›¾ç‰‡ä½ç½®
    pattern = r'(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'
    matches = re.findall(pattern, result_text, re.DOTALL)

    img_idx = 0
    for match in matches:
        if '<|ref|>image<|/ref|>' in match[0]:
            # ç”¨Markdownå›¾ç‰‡è¯­æ³•æ›¿æ¢
            if image_paths and img_idx < len(image_paths):
                img_path = image_paths[img_idx]

                # Gradioéœ€è¦ä½¿ç”¨HTML imgæ ‡ç­¾æ¥æ˜¾ç¤ºæœ¬åœ°å›¾ç‰‡
                # ä½¿ç”¨base64ç¼–ç åµŒå…¥å›¾ç‰‡
                try:
                    import base64
                    with open(img_path, 'rb') as f:
                        img_data = f.read()
                        img_base64 = base64.b64encode(img_data).decode('utf-8')

                    # æ£€æµ‹å›¾ç‰‡æ ¼å¼
                    img_ext = os.path.splitext(img_path)[1].lower()
                    if img_ext == '.png':
                        mime_type = 'image/png'
                    elif img_ext in ['.jpg', '.jpeg']:
                        mime_type = 'image/jpeg'
                    else:
                        mime_type = 'image/jpeg'

                    # ä½¿ç”¨base64åµŒå…¥çš„imgæ ‡ç­¾
                    img_markdown = f'\n\n<img src="data:{mime_type};base64,{img_base64}" alt="æå–çš„å›¾ç‰‡{img_idx+1}" style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 4px; padding: 5px;">\n\n'

                    print(f"å›¾ç‰‡{img_idx+1}å·²è½¬æ¢ä¸ºbase64åµŒå…¥ (å¤§å°: {len(img_base64)} bytes)")

                except Exception as e:
                    print(f"è½¬æ¢å›¾ç‰‡{img_idx+1}ä¸ºbase64å¤±è´¥: {e}")
                    img_markdown = f'\n\n[å›¾ç‰‡{img_idx+1}: {os.path.basename(img_path)}]\n\n'

                result_text = result_text.replace(match[0], img_markdown, 1)
                img_idx += 1
            else:
                result_text = result_text.replace(match[0], '\n[å›¾ç‰‡]\n', 1)
        else:
            # ç§»é™¤å…¶ä»–æ ‡æ³¨
            result_text = result_text.replace(match[0], '')

    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
    result_text = result_text.replace('\\coloneqq', ':=').replace('\\eqqcolon', '=:')
    result_text = result_text.replace('\n\n\n\n', '\n\n').replace('\n\n\n', '\n\n')

    # ç§»é™¤ç»“æŸæ ‡è®°
    if '<ï½œendâ–ofâ–sentenceï½œ>' in result_text:
        result_text = result_text.replace('<ï½œendâ–ofâ–sentenceï½œ>', '')

    return result_text.strip()


def create_pdf_markdown_with_images(raw_results_list, all_image_paths):
    """ä¸ºPDFåˆ›å»ºåŒ…å«å›¾ç‰‡çš„Markdown"""
    if not raw_results_list:
        return ""

    # åˆå¹¶æ‰€æœ‰åŸå§‹ç»“æœ
    combined_text = "\n".join(raw_results_list)

    # ä½¿ç”¨create_markdown_with_imageså¤„ç†
    return create_markdown_with_images(combined_text, all_image_paths)


def process_image_ocr_stream(image, prompt_type, base_size, image_size, crop_mode):
    """å¤„ç†å•å¼ å›¾ç‰‡çš„OCR - ç”Ÿæˆå™¨ç‰ˆæœ¬ï¼Œæ”¯æŒæµå¼è¾“å‡º"""
    if image is None:
        yield "è¯·ä¸Šä¼ å›¾ç‰‡", "", "è¯·ä¸Šä¼ å›¾ç‰‡", None
        return

    # è®¾ç½®prompt
    if prompt_type == "Free OCR":
        prompt = "<image>\nFree OCR. "
    else:  # Convert to Markdown
        prompt = "<image>\n<|grounding|>Convert the document to markdown. "

    # åˆ›å»ºæŒä¹…åŒ–çš„è¾“å‡ºç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_base_dir = os.path.join(script_dir, "gradio_outputs")
    session_dir = os.path.join(output_base_dir, f"session_{int(time.time() * 1000)}")
    os.makedirs(session_dir, exist_ok=True)

    try:
        tmpdir = session_dir
        # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡
        temp_image_path = os.path.join(tmpdir, "input_image.png")
        if isinstance(image, str):
            # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„
            temp_image_path = image
        else:
            # å¦‚æœæ˜¯PIL Imageæˆ–numpy array
            if not isinstance(image, Image.Image):
                image = Image.fromarray(image)
            image.save(temp_image_path)

        yield "æ­£åœ¨å¤„ç†å›¾ç‰‡...", "", "æ­£åœ¨å¤„ç†å›¾ç‰‡...", None

        # åˆ›å»ºæµå¼æ•è·å¯¹è±¡
        stream_capture = StreamCapture()

        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œæ¨¡å‹æ¨ç†
        result_container = {'result': None, 'error': None}

        def run_inference():
            try:
                stream_capture.start_capture()
                result = model.infer(
                    tokenizer,
                    prompt=prompt,
                    image_file=temp_image_path,
                    output_path=tmpdir,
                    base_size=int(base_size),
                    image_size=int(image_size),
                    crop_mode=crop_mode,
                    save_results=False,
                    test_compress=True
                )
                result_container['result'] = result
            except Exception as e:
                result_container['error'] = e
            finally:
                stream_capture.stop_capture()

        # å¯åŠ¨æ¨ç†çº¿ç¨‹
        inference_thread = threading.Thread(target=run_inference)
        inference_thread.start()

        # æµå¼è¾“å‡º
        accumulated_text = ""
        last_update = time.time()

        while inference_thread.is_alive() or not stream_capture.queue.empty():
            try:
                # å°è¯•ä»é˜Ÿåˆ—è·å–æ–°æ–‡æœ¬
                text = stream_capture.queue.get(timeout=0.1)
                accumulated_text += text

                # æ¸…ç†åçš„æ–‡æœ¬
                cleaned_text = clean_ocr_output(accumulated_text)

                # æ¯0.1ç§’æ›´æ–°ä¸€æ¬¡ç•Œé¢ï¼ˆæµå¼é˜¶æ®µæš‚ä¸æ˜¾ç¤ºå›¾ç‰‡ï¼‰
                current_time = time.time()
                if current_time - last_update >= 0.1:
                    yield cleaned_text, accumulated_text, cleaned_text + "\n\n*è¯†åˆ«ä¸­...*", None
                    last_update = current_time

            except:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                time.sleep(0.05)

        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        inference_thread.join()

        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if result_container['error']:
            import traceback
            error_msg = f"OCRå¤„ç†å‡ºé”™: {str(result_container['error'])}\n\n{traceback.format_exc()}"
            yield error_msg, "", error_msg, None
            return

        # è·å–æœ€ç»ˆç»“æœ
        final_captured = stream_capture.stop_capture()

        # ä½¿ç”¨è¿”å›å€¼æˆ–æ•è·çš„è¾“å‡º
        if result_container['result'] is not None and result_container['result'] != "":
            final_result = result_container['result']
        else:
            final_result = final_captured

        if not final_result:
            yield "OCRå¤„ç†å®Œæˆï¼Œä½†æ¨¡å‹æœªè¿”å›ç»“æœã€‚", "", "OCRå¤„ç†å®Œæˆï¼Œä½†æ¨¡å‹æœªè¿”å›ç»“æœã€‚", None
            return

        # å…ˆè¾“å‡ºè¯†åˆ«å®Œæˆçš„æç¤ºï¼Œå›¾ç‰‡æ­£åœ¨å¤„ç†ä¸­
        cleaned_temp = clean_ocr_output(final_result)
        yield cleaned_temp, final_result, cleaned_temp + "\n\n*æ­£åœ¨æå–å›¾ç‰‡...*", None

        # è£åˆ‡å›¾ç‰‡
        images_dir = os.path.join(tmpdir, "extracted_images")
        cropped_image_paths = crop_images_from_text(temp_image_path, final_result, images_dir, page_idx=0)

        print(f"æå–çš„å›¾ç‰‡æ•°é‡: {len(cropped_image_paths)}")
        print(f"å›¾ç‰‡è·¯å¾„: {cropped_image_paths}")

        # æ¸…ç†è¾“å‡ºï¼ˆçº¯æ–‡æœ¬ï¼‰
        cleaned_result = clean_ocr_output(final_result)

        # ä¸ºMarkdownåˆ›å»ºå¸¦å›¾ç‰‡é“¾æ¥çš„ç‰ˆæœ¬ï¼ˆå›¾ç‰‡å·²ç»è£åˆ‡å®Œæˆï¼‰
        markdown_result = create_markdown_with_images(final_result, cropped_image_paths)

        print(f"Markdownç»“æœå‰500å­—ç¬¦:\n{markdown_result[:500]}")

        # åˆ›å»ºå›¾ç‰‡ç”»å»Š
        gallery_images = cropped_image_paths if cropped_image_paths else None

        # æœ€ç»ˆè¾“å‡ºï¼ŒåŒ…å«å›¾ç‰‡
        yield cleaned_result, final_result, markdown_result, gallery_images

    except Exception as e:
        import traceback
        error_msg = f"OCRå¤„ç†å‡ºé”™: {str(e)}\n\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
        yield error_msg, "", error_msg, None


def process_pdf_ocr_stream(pdf_file, prompt_type, base_size, image_size, crop_mode):
    """å¤„ç†PDFæ–‡ä»¶çš„OCR - ç”Ÿæˆå™¨ç‰ˆæœ¬ï¼Œæ”¯æŒæµå¼è¾“å‡º"""
    if pdf_file is None:
        yield "è¯·ä¸Šä¼ PDFæ–‡ä»¶", "", "è¯·ä¸Šä¼ PDFæ–‡ä»¶", None
        return

    # è®¾ç½®prompt
    if prompt_type == "Free OCR":
        prompt = "<image>\nFree OCR. "
    else:  # Convert to Markdown
        prompt = "<image>\n<|grounding|>Convert the document to markdown. "

    # åˆ›å»ºæŒä¹…åŒ–çš„è¾“å‡ºç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_base_dir = os.path.join(script_dir, "gradio_outputs")
    session_dir = os.path.join(output_base_dir, f"session_{int(time.time() * 1000)}")
    os.makedirs(session_dir, exist_ok=True)

    try:
        tmpdir = session_dir

        # å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡
        yield "æ­£åœ¨åŠ è½½PDF...", "", "æ­£åœ¨åŠ è½½PDF...", None
        images = pdf_to_images(pdf_file.name)

        yield f"PDFåŠ è½½å®Œæˆï¼Œå…± {len(images)} é¡µï¼Œå¼€å§‹è¯†åˆ«...", "", f"PDFåŠ è½½å®Œæˆï¼Œå…± {len(images)} é¡µ", None

        all_results = []
        all_raw_results = []
        all_cleaned_results = []
        all_cropped_images = []  # å­˜å‚¨æ‰€æœ‰è£åˆ‡çš„å›¾ç‰‡

        images_base_dir = os.path.join(tmpdir, "extracted_images")

        for idx, img in enumerate(images):
            temp_image_path = os.path.join(tmpdir, f"page_{idx}.png")
            img.save(temp_image_path)

            page_header = f"\n{'='*50}\nç¬¬ {idx+1}/{len(images)} é¡µ\n{'='*50}\n"

            # æ›´æ–°è¿›åº¦
            progress_msg = "\n".join(all_cleaned_results) + page_header + "æ­£åœ¨è¯†åˆ«..."
            yield progress_msg, "", progress_msg, all_cropped_images if all_cropped_images else None

            # åˆ›å»ºæµå¼æ•è·å¯¹è±¡
            stream_capture = StreamCapture()

            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œæ¨¡å‹æ¨ç†
            result_container = {'result': None, 'error': None}

            def run_inference():
                try:
                    stream_capture.start_capture()
                    result = model.infer(
                        tokenizer,
                        prompt=prompt,
                        image_file=temp_image_path,
                        output_path=tmpdir,
                        base_size=int(base_size),
                        image_size=int(image_size),
                        crop_mode=crop_mode,
                        save_results=False,
                        test_compress=True
                    )
                    result_container['result'] = result
                except Exception as e:
                    result_container['error'] = e
                finally:
                    stream_capture.stop_capture()

            # å¯åŠ¨æ¨ç†çº¿ç¨‹
            inference_thread = threading.Thread(target=run_inference)
            inference_thread.start()

            # æµå¼è¾“å‡ºå½“å‰é¡µ
            page_text = ""
            last_update = time.time()

            while inference_thread.is_alive() or not stream_capture.queue.empty():
                try:
                    text = stream_capture.queue.get(timeout=0.1)
                    page_text += text

                    # æ¸…ç†åçš„æ–‡æœ¬
                    cleaned_page = clean_ocr_output(page_text)

                    # æ›´æ–°ç•Œé¢
                    current_time = time.time()
                    if current_time - last_update >= 0.1:
                        current_display = "\n".join(all_cleaned_results) + page_header + cleaned_page
                        yield current_display, "", current_display, all_cropped_images if all_cropped_images else None
                        last_update = current_time

                except:
                    time.sleep(0.05)

            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            inference_thread.join()

            # è·å–æœ€ç»ˆç»“æœ
            final_captured = stream_capture.stop_capture()

            if result_container['result'] is not None and result_container['result'] != "":
                final_result = result_container['result']
            else:
                final_result = final_captured

            if not final_result:
                final_result = f"[ç¬¬ {idx+1} é¡µå¤„ç†å¤±è´¥]"

            # è£åˆ‡å½“å‰é¡µçš„å›¾ç‰‡
            page_cropped_images = crop_images_from_text(temp_image_path, final_result, images_base_dir, page_idx=idx)
            all_cropped_images.extend(page_cropped_images)

            print(f"ç¬¬ {idx+1} é¡µæå–å›¾ç‰‡æ•°: {len(page_cropped_images)}")

            # æ¸…ç†è¾“å‡º
            cleaned_result = clean_ocr_output(final_result)

            all_cleaned_results.append(page_header + cleaned_result)
            all_raw_results.append(f"{page_header}(åŸå§‹è¾“å‡º)\n{final_result}")

        final_clean = "\n".join(all_cleaned_results)
        final_raw = "\n".join(all_raw_results)

        print(f"æ€»å…±æå–å›¾ç‰‡æ•°: {len(all_cropped_images)}")
        print(f"å›¾ç‰‡è·¯å¾„: {all_cropped_images}")

        # åˆ›å»ºåŒ…å«å›¾ç‰‡çš„Markdownç‰ˆæœ¬
        # å¯¹äºPDFï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°æ„å»ºå¸¦å›¾ç‰‡çš„Markdown
        final_markdown = create_pdf_markdown_with_images(all_raw_results, all_cropped_images)

        yield final_clean, final_raw, final_markdown, all_cropped_images if all_cropped_images else None

    except Exception as e:
        import traceback
        error_msg = f"PDFå¤„ç†å‡ºé”™: {str(e)}\n{traceback.format_exc()}"
        yield error_msg, "", error_msg, None


def process_file_stream(file, prompt_type, base_size, image_size, crop_mode):
    """ç»Ÿä¸€å¤„ç†å›¾ç‰‡æˆ–PDFæ–‡ä»¶ - ç”Ÿæˆå™¨ç‰ˆæœ¬"""
    if file is None:
        yield "è¯·ä¸Šä¼ æ–‡ä»¶", "", "è¯·ä¸Šä¼ æ–‡ä»¶", None
        return

    # åˆ¤æ–­æ–‡ä»¶ç±»å‹
    file_path = file.name if hasattr(file, 'name') else file
    file_ext = Path(file_path).suffix.lower()

    if file_ext == '.pdf':
        yield from process_pdf_ocr_stream(file, prompt_type, base_size, image_size, crop_mode)
    elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']:
        # å¯¹äºå›¾ç‰‡æ–‡ä»¶,ç›´æ¥ä½¿ç”¨è·¯å¾„
        yield from process_image_ocr_stream(file_path, prompt_type, base_size, image_size, crop_mode)
    else:
        yield "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼,è¯·ä¸Šä¼ å›¾ç‰‡(jpg/png/bmpç­‰)æˆ–PDFæ–‡ä»¶", "", "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼", None


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="DeepSeek OCR", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ” DeepSeek OCR æ–‡æ¡£è¯†åˆ«")
    gr.Markdown("æ”¯æŒä¸Šä¼ å›¾ç‰‡æˆ–PDFæ–‡ä»¶è¿›è¡ŒOCRè¯†åˆ«ï¼Œå®æ—¶æµå¼è¾“å‡ºï¼Œæ”¯æŒMarkdownæ¸²æŸ“")

    with gr.Row():
        with gr.Column(scale=1):
            # æ–‡ä»¶ä¸Šä¼ 
            file_input = gr.File(
                label="ğŸ“ ä¸Šä¼ å›¾ç‰‡æˆ–PDFæ–‡ä»¶",
                file_types=[".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp", ".pdf"]
            )

            # OCRå‚æ•°è®¾ç½®
            prompt_type = gr.Radio(
                choices=["Free OCR", "Convert to Markdown"],
                value="Convert to Markdown",
                label="ğŸ¯ OCRæ¨¡å¼"
            )

            with gr.Accordion("âš™ï¸ é«˜çº§è®¾ç½®", open=False):
                base_size = gr.Slider(
                    minimum=512,
                    maximum=1280,
                    value=1024,
                    step=64,
                    label="Base Size (åŸºç¡€å°ºå¯¸)"
                )
                image_size = gr.Slider(
                    minimum=512,
                    maximum=1280,
                    value=640,
                    step=64,
                    label="Image Size (å›¾åƒå°ºå¯¸)"
                )
                crop_mode = gr.Checkbox(
                    value=True,
                    label="Crop Mode (è£å‰ªæ¨¡å¼)"
                )

                gr.Markdown("""
                **æ¨¡å‹å°ºå¯¸é¢„è®¾å‚è€ƒ:**
                - Tiny: base_size=512, image_size=512, crop_mode=False
                - Small: base_size=640, image_size=640, crop_mode=False
                - Base: base_size=1024, image_size=1024, crop_mode=False
                - Large: base_size=1280, image_size=1280, crop_mode=False
                - Gundam (æ¨è): base_size=1024, image_size=640, crop_mode=True
                """)

            # æ‰§è¡ŒæŒ‰é’®
            submit_btn = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
            stop_btn = gr.Button("â¹ï¸ åœæ­¢", variant="stop", size="lg")

        with gr.Column(scale=2):
            # ç»“æœæ˜¾ç¤º
            with gr.Tabs():
                with gr.Tab("ğŸ“ Markdownæ¸²æŸ“"):
                    output_markdown = gr.Markdown(
                        label="Markdownæ¸²æŸ“ç»“æœ",
                        value="ç­‰å¾…è¯†åˆ«ç»“æœ..."
                    )

                with gr.Tab("ğŸ“„ çº¯æ–‡æœ¬"):
                    output_clean = gr.Textbox(
                        label="OCRè¯†åˆ«ç»“æœï¼ˆå·²æ¸…ç†ï¼‰",
                        lines=30,
                        max_lines=50,
                        show_copy_button=True
                    )

                with gr.Tab("ğŸ”§ åŸå§‹è¾“å‡º"):
                    output_raw = gr.Textbox(
                        label="åŸå§‹OCRè¾“å‡ºï¼ˆåŒ…å«æ ‡æ³¨ä¿¡æ¯ï¼‰",
                        lines=30,
                        max_lines=50,
                        show_copy_button=True
                    )

                with gr.Tab("ğŸ–¼ï¸ æå–çš„å›¾ç‰‡"):
                    output_gallery = gr.Gallery(
                        label="æ–‡æ¡£ä¸­è¯†åˆ«å¹¶æå–çš„å›¾ç‰‡",
                        columns=3,
                        rows=2,
                        height="auto",
                        object_fit="contain",
                        show_download_button=True
                    )

    # ç¤ºä¾‹
    gr.Markdown("### ğŸ“š ç¤ºä¾‹æ–‡ä»¶")

    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    example_image = os.path.join(script_dir, "ç¤ºä¾‹å›¾ç‰‡.png")
    example_pdf = os.path.join(script_dir, "DeepSeek_OCR_paper-p1.pdf")

    # åªæ·»åŠ å­˜åœ¨çš„ç¤ºä¾‹
    examples_list = []
    if os.path.exists(example_image):
        examples_list.append([example_image, "Convert to Markdown", 1024, 640, True])
    if os.path.exists(example_pdf):
        examples_list.append([example_pdf, "Convert to Markdown", 1024, 640, True])

    if examples_list:
        gr.Examples(
            examples=examples_list,
            inputs=[file_input, prompt_type, base_size, image_size, crop_mode],
            label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿä½“éªŒ"
        )

    gr.Markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
    gr.Markdown("""
    - è¯†åˆ«è¿‡ç¨‹ä¸­ä¼š**å®æ—¶æµå¼æ˜¾ç¤º**ç»“æœ
    - **Markdownæ¸²æŸ“**æ ‡ç­¾é¡µå¯ä»¥çœ‹åˆ°æ ¼å¼åŒ–åçš„æ•ˆæœ
    - **çº¯æ–‡æœ¬**æ ‡ç­¾é¡µå¯ä»¥å¤åˆ¶æ–‡æœ¬å†…å®¹
    - **åŸå§‹è¾“å‡º**æ ‡ç­¾é¡µåŒ…å«æ¨¡å‹çš„åŸå§‹æ ‡æ³¨ä¿¡æ¯
    - **æå–çš„å›¾ç‰‡**æ ‡ç­¾é¡µæ˜¾ç¤ºæ–‡æ¡£ä¸­è¯†åˆ«åˆ°çš„æ‰€æœ‰å›¾ç‰‡ï¼Œæ”¯æŒä¸‹è½½
    - æ”¯æŒPDFå¤šé¡µæ–‡æ¡£ï¼Œä¼šé€é¡µè¯†åˆ«å¹¶æ˜¾ç¤ºè¿›åº¦
    """)

    # ç»‘å®šäº‹ä»¶
    submit_event = submit_btn.click(
        fn=process_file_stream,
        inputs=[file_input, prompt_type, base_size, image_size, crop_mode],
        outputs=[output_clean, output_raw, output_markdown, output_gallery]
    )

    # åœæ­¢æŒ‰é’®ï¼ˆå–æ¶ˆå½“å‰ä»»åŠ¡ï¼‰
    stop_btn.click(fn=None, inputs=None, outputs=None, cancels=[submit_event])


if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True
    )
